import os
from chromadb import PersistentClient
from chromadb import Documents, EmbeddingFunction, Embeddings
import google.generativeai as genai  
import json
from datetime import datetime, date, timedelta
import re
from typing import Optional
import dotenv
dotenv.load_dotenv()
# âœ… ì„¤ì •

CHROMA_DIR = "rag/chroma_db"
COLLECTION_NAME = "knou_chunks"
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# API í‚¤ ì „ì—­ ì„¤ì •
genai.configure(api_key=GEMINI_API_KEY)

# âœ… Gemini ì„ë² ë”© í•¨ìˆ˜ (ìµœì‹  API ë°©ì‹)
class GeminiEmbeddingFunction(EmbeddingFunction):
    def __init__(self):
        self.model = "models/text-embedding-004"
    
    def __call__(self, input: Documents) -> Embeddings:
        try:
            # ë°°ì¹˜ ì„ë² ë”© ìš”ì²­
            result = genai.embed_content(
                model=self.model,
                content=input,
                task_type="retrieval_document"
            )
            return result['embedding']
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            return [[0.0] * 768 for _ in input]

class KNOUChatbot:
    def __init__(self):
        print("ğŸ¤– KNOU ì±—ë´‡ì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.chroma_client = PersistentClient(path=CHROMA_DIR)
        self.embedding_func = GeminiEmbeddingFunction()
        
        # ì»¬ë ‰ì…˜ ë¡œë“œ
        try:
            self.collection = self.chroma_client.get_collection(
                name=COLLECTION_NAME,
                embedding_function=self.embedding_func
            )
            print(f"âœ… ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ: {self.collection.count()}ê°œ ì²­í¬")
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return
        
        # Gemini ìƒì„± ëª¨ë¸ (ìµœì‹  ë°©ì‹)
        self.gen_model = genai.GenerativeModel("gemini-1.5-flash")
        
        print("ğŸ¯ KNOU ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ!\n")

    def _parse_date_string(self, date_str: str) -> Optional[date]:
        """Helper to parse various date string formats into a date object."""
        if not date_str:
            return None
        
        # ë°ì´í„°ì˜ ì£¼ìš” ì—°ë„ëŠ” 2025ë…„ì´ë¯€ë¡œ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
        context_year = 2025 

        # Handle ranges, use start date
        if "~" in date_str:
            date_str = date_str.split("~")[0].strip()

        # Try common formats
        date_formats = [
            "%Y-%m-%d",      # 2025-07-16
            "%Y.%m.%d",      # 2025.07.16  
            "%Y/%m/%d",      # 2025/07/16
        ]
        
        dt_obj = None
        for fmt in date_formats:
            try:
                dt_obj = datetime.strptime(date_str, fmt).date()
                return dt_obj
            except ValueError:
                continue
        
        # Try partial formats (e.g., "07.25", "07/25")
        try:
            # "07.25" format
            if len(date_str.split('.')) == 2:
                month, day = map(int, date_str.split('.'))
                # í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—°ë„ ì¶”ì •
                current_date = date.today()
                # 12ì›”ì´ë©´ì„œ í˜„ì¬ê°€ 1-6ì›”ì´ë©´ ì‘ë…„, ì•„ë‹ˆë©´ ì˜¬í•´
                if month == 12 and current_date.month <= 6:
                    year = current_date.year - 1
                # 1-6ì›”ì´ë©´ì„œ í˜„ì¬ê°€ 7-12ì›”ì´ë©´ ë‚´ë…„, ì•„ë‹ˆë©´ ì˜¬í•´  
                elif month <= 6 and current_date.month >= 7:
                    year = current_date.year + 1
                else:
                    year = current_date.year
                return date(year, month, day)
            # "07/25" format
            elif len(date_str.split('/')) == 2:
                month, day = map(int, date_str.split('/'))
                # ë™ì¼í•œ ë¡œì§ ì ìš©
                current_date = date.today()
                if month == 12 and current_date.month <= 6:
                    year = current_date.year - 1
                elif month <= 6 and current_date.month >= 7:
                    year = current_date.year + 1
                else:
                    year = current_date.year
                return date(year, month, day)
        except (ValueError, TypeError):
            pass
            
        return None

    def extract_query_date(self, query: str) -> Optional[date]:
        """Extracts a specific date (month and day) from the user query."""
        # "7ì›” 25ì¼", "7ì›”25ì¼", "7 ì›” 25 ì¼" etc.
        match = re.search(r'(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼', query)
        if match:
            month, day = int(match.group(1)), int(match.group(2))
            # ë°ì´í„°ì˜ ì£¼ìš” ì—°ë„ëŠ” 2025ë…„ì´ë¯€ë¡œ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
            year = 2025 
            try:
                return date(year, month, day)
            except ValueError: # Invalid date like Feb 30
                return None
        return None

    def is_latest_query(self, query: str) -> bool:
        """ì‚¬ìš©ìê°€ ìµœì‹ /ìµœê·¼ ê³µì§€ë¥¼ ìš”ì²­í•˜ëŠ”ì§€ íŒë‹¨"""
        latest_keywords = [
            'ìµœì‹ ', 'ìµœê·¼', 'ìƒˆë¡œìš´', 'ê°€ì¥', 'ì‹ ê·œ', 'ì—…ë°ì´íŠ¸', 
            'ì´ë²ˆì£¼', 'ì´ë²ˆë‹¬', 'ì˜¤ëŠ˜', 'ì–´ì œ', 'ìµœì‹ ê³µì§€', 'ìµœê·¼ê³µì§€', 
            'ìƒˆê³µì§€', 'ìµœì‹ ê³µê³ ', 'ìµœê·¼ê³µê³ ', 'ìƒˆê³µê³ ', 'ìµœì‹ ì†Œì‹'
        ]
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in latest_keywords)
    
    def get_recent_documents(self, days_back: int = 7) -> list:
        """ìµœê·¼ Nì¼ ì´ë‚´ì˜ ë¬¸ì„œë“¤ì„ ë‚ ì§œìˆœìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            today = date.today()
            cutoff_date = today - timedelta(days=days_back)
            
            all_docs_data = self.collection.get(include=["documents", "metadatas"])
            recent_docs = []
            
            for i in range(len(all_docs_data['ids'])):
                meta = all_docs_data['metadatas'][i]
                doc_date_str = meta.get('date')
                
                if doc_date_str:
                    parsed_doc_date = self._parse_date_string(doc_date_str)
                    if parsed_doc_date and parsed_doc_date >= cutoff_date:
                        recent_docs.append({
                            'id': all_docs_data['ids'][i],
                            'document': all_docs_data['documents'][i],
                            'metadata': meta,
                            'parsed_date': parsed_doc_date
                        })
            
            # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
            recent_docs.sort(key=lambda x: x['parsed_date'], reverse=True)
            
            print(f"ğŸ“… ìµœê·¼ {days_back}ì¼ ì´ë‚´ ë¬¸ì„œ: {len(recent_docs)}ê°œ ë°œê²¬")
            
            if recent_docs:
                final_ids = [d['id'] for d in recent_docs[:10]]  # ìƒìœ„ 10ê°œë§Œ
                final_docs = [d['document'] for d in recent_docs[:10]]
                final_metas = [d['metadata'] for d in recent_docs[:10]]
                
                return {
                    'ids': [final_ids],
                    'documents': [final_docs],
                    'metadatas': [final_metas]
                }
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ ìµœê·¼ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def get_data_date_info(self):
        """ì‹œìŠ¤í…œ ë°ì´í„°ì˜ ë‚ ì§œ ë²”ìœ„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            all_data = self.collection.get(include=['metadatas'])
            dates = set()
            
            for meta in all_data['metadatas']:
                if meta and meta.get('date'):
                    dates.add(meta['date'])
            
            if dates:
                sorted_dates = sorted(dates)
                return {
                    'latest': sorted_dates[-1],
                    'oldest': sorted_dates[0],
                    'total_dates': len(sorted_dates)
                }
            return None
        except Exception as e:
            print(f"âš ï¸ ë‚ ì§œ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None

    def preprocess_query(self, query: str) -> str:
        """ğŸš€ ë¹ ë¥¸ ê°œì„ : ì¿¼ë¦¬ ì „ì²˜ë¦¬ - ì¼ë°˜ ìš©ì–´ë¥¼ ê³µì‹ ìš©ì–´ë¡œ ë³€í™˜"""
        
        # ìš©ì–´ ì •ê·œí™” ë§¤í•‘
        term_mappings = {
            'í•™ë¹„': 'ë“±ë¡ê¸ˆ',
            'ë“±ë¡ë¹„': 'ë“±ë¡ê¸ˆ', 
            'í•™ìŠµë¹„': 'ë“±ë¡ê¸ˆ',
            'ë‚©ë¶€': 'ë“±ë¡ê¸ˆ ë‚©ë¶€',
            'ì¥í•™': 'ì¥í•™ê¸ˆ',
            'ì„±ì ìš°ìˆ˜': 'ì„±ì ìš°ìˆ˜ì¥í•™',
            'ìš°ìˆ˜ì¥í•™': 'ì„±ì ìš°ìˆ˜ì¥í•™',
            'ìˆ˜ê°•': 'ìˆ˜ê°•ì‹ ì²­',
            'ê³¼ëª©ì‹ ì²­': 'ìˆ˜ê°•ì‹ ì²­',
            'ì‹œí—˜': 'ì¶œì„ì‹œí—˜',
            'ì¡¸ì—…': 'ì¡¸ì—…ë…¼ë¬¸',
            '2í•™ê¸°': '2025í•™ë…„ë„ 2í•™ê¸°',
            '1í•™ê¸°': '2025í•™ë…„ë„ 1í•™ê¸°'
        }
        
        enhanced_query = query
        for original, replacement in term_mappings.items():
            if original in query and replacement not in query:
                enhanced_query = enhanced_query.replace(original, f"{original} {replacement}")
        
        return enhanced_query
    
    def get_enhanced_keywords(self, query: str) -> set:
        """ğŸš€ ë¹ ë¥¸ ê°œì„ : ëŒ€í­ í™•ì¥ëœ í‚¤ì›Œë“œ ë§¤í•‘"""
        
        query_lower = query.lower()
        enhanced_keywords = set(query_lower.split())
        
        # ğŸ”¥ NEW: ìµœì‹ ì„± ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¥
        if any(word in query_lower for word in ['ìµœì‹ ', 'ìµœê·¼', 'ìƒˆë¡œìš´', 'ê°€ì¥', 'ì‹ ê·œ', 'ì—…ë°ì´íŠ¸', 'ê³µì§€', 'ìµœì‹ ê³µì§€', 'ìµœê·¼ê³µì§€', 'ìƒˆê³µì§€']):
            enhanced_keywords.update([
                'ìµœì‹ ', 'ìµœê·¼', 'ìƒˆë¡œìš´', 'ì‹ ê·œ', 'ì—…ë°ì´íŠ¸', 'ê³µì§€',
                'ìµœì‹ ê³µì§€', 'ìµœê·¼ê³µì§€', 'ìƒˆê³µì§€'
            ])
        
        # ë“±ë¡ê¸ˆ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¥
        if any(word in query_lower for word in ['ë“±ë¡', 'í•™ë¹„', 'ë‚©ë¶€', 'ë“±ë¡ê¸ˆ']):
            enhanced_keywords.update([
                'ë“±ë¡ê¸ˆ', 'í•™ë¹„', 'ë‚©ë¶€', 'ìˆ˜ë‚©', 'ë“±ë¡ë¹„', 'í•™ìŠµë¹„', 
                'ë“±ë¡ê¸ˆë‚©ë¶€', 'ë“±ë¡ê¸ˆì•ˆë‚´', 'ë“±ë¡ê¸ˆìˆ˜ë‚©', 'ë“±ë¡'
            ])
        
        # ì¥í•™ê¸ˆ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¥  
        if any(word in query_lower for word in ['ì¥í•™', 'ì„±ì ìš°ìˆ˜', 'ì„±ì ', 'ìš°ìˆ˜']):
            enhanced_keywords.update([
                'ì¥í•™ê¸ˆ', 'ì¥í•™ìƒ', 'ì„±ì ìš°ìˆ˜ì¥í•™', 'ì„±ì ìš°ìˆ˜', 'ì¥í•™',
                'ìš°ìˆ˜ì¥í•™', 'ì¥í•™í˜œíƒ', 'ì¥í•™ì„ ë°œ', 'ì¥í•™ì•ˆë‚´'
            ])
        
        # ìˆ˜ê°• ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¥
        if any(word in query_lower for word in ['ìˆ˜ê°•', 'ê³¼ëª©', 'ì‹ ì²­']):
            enhanced_keywords.update([
                'ìˆ˜ê°•ì‹ ì²­', 'ê³¼ëª©ì‹ ì²­', 'ìˆ˜ê°•', 'ê³¼ëª©', 'ì‹ ì²­',
                'ìˆ˜ê°•ì•ˆë‚´', 'ì‹ ì²­ì•ˆë‚´', 'ìˆ˜ê°•ë°©ë²•'
            ])
        
        # ì‹œí—˜ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¥
        if any(word in query_lower for word in ['ì‹œí—˜', 'í‰ê°€', 'ì¶œì„']):
            enhanced_keywords.update([
                'ì‹œí—˜', 'ì¶œì„ì‹œí—˜', 'í‰ê°€', 'ì‹œí—˜ì•ˆë‚´', 'ì‹œí—˜ì¼ì •',
                'ê¸°ë§ì‹œí—˜', 'ì¤‘ê°„ì‹œí—˜', 'ì‹œí—˜ë°©ë²•'
            ])
        
        # ì‹œê°„ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¥
        if any(word in query_lower for word in ['2025', '2í•™ê¸°', '1í•™ê¸°']):
            enhanced_keywords.update([
                '2025í•™ë…„ë„', '2025ë…„', '2í•™ê¸°', '1í•™ê¸°',
                '2025í•™ë…„ë„ 2í•™ê¸°', '2025í•™ë…„ë„ 1í•™ê¸°'
            ])
        
        return enhanced_keywords
    
    def get_exact_phrases(self, query: str) -> list:
        """ğŸš€ ë¹ ë¥¸ ê°œì„ : ì •í™•í•œ êµ¬ë¬¸ ë§¤ì¹­ì„ ìœ„í•œ í•µì‹¬ êµ¬ë¬¸ ì¶”ì¶œ"""
        
        exact_phrases = []
        query_lower = query.lower()
        
        # í•µì‹¬ êµ¬ë¬¸ íŒ¨í„´ë“¤
        key_phrases = [
            'ë“±ë¡ê¸ˆ ë‚©ë¶€', 'ë“±ë¡ê¸ˆ ì•ˆë‚´', 'ë“±ë¡ê¸ˆë‚©ë¶€ì•ˆë‚´',
            'ì¥í•™ê¸ˆ ì„ ë°œ', 'ì„±ì ìš°ìˆ˜ì¥í•™', 'ì¥í•™ìƒ ì„ ë°œ',
            'ìˆ˜ê°•ì‹ ì²­', 'ê³¼ëª©ì‹ ì²­', 'ìˆ˜ê°• ì•ˆë‚´',
            'ì‹œí—˜ ì•ˆë‚´', 'ì¶œì„ì‹œí—˜', 'ì‹œí—˜ì¼ì •',
            '2025í•™ë…„ë„ 2í•™ê¸°', '2í•™ê¸°', '2025ë…„ 2í•™ê¸°'
        ]
        
        for phrase in key_phrases:
            if phrase in query_lower:
                exact_phrases.append(phrase)
        
        return exact_phrases

    def expand_query(self, query: str) -> list[str]:
        """LLMì„ ì‚¬ìš©í•´ ê²€ìƒ‰ì„ ìœ„í•œ ë‹¤ì–‘í•œ ì§ˆë¬¸ ìƒì„± (ì˜¤ëŠ˜ ë‚ ì§œ ìë™ í¬í•¨)"""
        
        today = date.today().strftime("%Y-%m-%d")
        
        prompt = f"""ë‹¹ì‹ ì€ ë²¡í„° ê²€ìƒ‰ì— ìµœì í™”ëœ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ì„œ, ê·¸ ì˜ë¯¸ë¥¼ ë‹¤ì–‘í•œ ê°ë„ì—ì„œ í¬ì°©í•  ìˆ˜ ìˆëŠ” 3ê°œì˜ êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ì¬ì‘ì„±í•´ì£¼ì„¸ìš”.

**ì¤‘ìš”: ì˜¤ëŠ˜ì€ {today}ì…ë‹ˆë‹¤. ì´ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  ì •ë³´ì™€ ê´€ë ¨ì„±ì´ ë†’ì€ ì§ˆë¬¸ìœ¼ë¡œ ì¬ì‘ì„±í•´ì£¼ì„¸ìš”.**

ê²°ê³¼ëŠ” ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ë²ˆí˜¸ ëª©ë¡ìœ¼ë¡œë§Œ ì œê³µí•´ì£¼ì„¸ìš”.

ì›ë³¸ ì§ˆë¬¸: "{query}"

ì¬ì‘ì„±ëœ ì§ˆë¬¸:
"""
        try:
            response = self.gen_model.generate_content(prompt)
            
            expanded_queries = [line.strip().split('. ', 1)[1] for line in response.text.strip().split('\n') if '. ' in line]
            
            enhanced_query = f"[ì˜¤ëŠ˜: {today}] {query}"
            all_queries = [enhanced_query] + expanded_queries
            print(f"ğŸ’¡ ì¿¼ë¦¬ í™•ì¥ (ì˜¤ëŠ˜: {today}): {all_queries[0]}")
            return all_queries

        except Exception as e:
            print(f"âš ï¸ ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨ ({e}), ì›ë³¸ ì§ˆë¬¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            enhanced_query = f"[ì˜¤ëŠ˜: {today}] {query}"
            return [enhanced_query]
    
    def calculate_date_weight(self, doc_date: str, current_date: str = None) -> float:
        """ë‚ ì§œ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° - ìµœì‹  ë¬¸ì„œì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜"""
        if not current_date:
            curr_dt = date.today()
        else:
            try:
                curr_dt = datetime.strptime(current_date, "%Y-%m-%d").date()
            except ValueError:
                curr_dt = date.today()
        
        try:
            doc_dt = self._parse_date_string(doc_date)
            
            if not doc_dt:
                return 0.3  # ê¸°ë³¸ ê°€ì¤‘ì¹˜
            
            # ë‚ ì§œ ì°¨ì´ ê³„ì‚° (ì¼ ë‹¨ìœ„)
            days_diff = abs((curr_dt - doc_dt).days)
            
            # ğŸš€ ë¹ ë¥¸ ê°œì„ : ë” ê°•ë ¥í•œ ìµœì‹ ì„± ê°€ì¤‘ì¹˜
            if days_diff <= 7:
                return 1.5  # ìµœê·¼ ì¼ì£¼ì¼ì€ ë” ë†’ì€ ê°€ì¤‘ì¹˜
            elif days_diff <= 30:
                return 1.2  # ìµœê·¼ í•œ ë‹¬
            elif days_diff <= 90:
                return 1.0  # ìµœê·¼ 3ê°œì›”
            elif days_diff <= 180:
                return 0.7  # ìµœê·¼ 6ê°œì›”
            elif days_diff <= 365:
                return 0.5  # ìµœê·¼ 1ë…„
            else:
                return 0.3  # 1ë…„ ì´ìƒ
                
        except Exception as e:
            print(f"âš ï¸ ë‚ ì§œ ì²˜ë¦¬ ì˜¤ë¥˜ ({doc_date}): {e}")
            return 0.3  # ê¸°ë³¸ ê°€ì¤‘ì¹˜

    def search_documents(self, query: str, n_results: int = 5):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: LLMì¿¼ë¦¬í™•ì¥(Vector)ê³¼ í‚¤ì›Œë“œ(Full-text) ê²€ìƒ‰ì„ RRFë¡œ ê²°í•© + ë‚ ì§œ ê¸°ë°˜ ì •ë ¬"""

        # ğŸ”¥ NEW: ìµœì‹  ê³µì§€ ìš”ì²­ ìš°ì„  ì²˜ë¦¬
        if self.is_latest_query(query):
            print("âœ¨ 'ìµœì‹  ê³µì§€' ì¿¼ë¦¬ë¡œ ê°ì§€, ìµœê·¼ 1ì£¼ì¼ ë¬¸ì„œ ìš°ì„  ê²€ìƒ‰...")
            recent_results = self.get_recent_documents(days_back=7)
            if recent_results:
                return recent_results
            else:
                print("â„¹ï¸ ìµœê·¼ 1ì£¼ì¼ ë‚´ ë¬¸ì„œê°€ ì—†ì–´ ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")

        # ğŸ”¥ NEW: íŠ¹ì • ë‚ ì§œ ì¿¼ë¦¬ ìš°ì„  ì²˜ë¦¬
        query_date = self.extract_query_date(query)
        if query_date:
            print(f"ğŸ¯ íŠ¹ì • ë‚ ì§œ ì¿¼ë¦¬ ê°ì§€: {query_date.strftime('%Y-%m-%d')}")
            try:
                all_docs_data = self.collection.get(include=["documents", "metadatas"])
                
                matched_docs = []
                for i in range(len(all_docs_data['ids'])):
                    meta = all_docs_data['metadatas'][i]
                    doc_date_str = meta.get('date')
                    if doc_date_str:
                        parsed_doc_date = self._parse_date_string(doc_date_str)
                        if parsed_doc_date and parsed_doc_date == query_date:
                            matched_docs.append({
                                'id': all_docs_data['ids'][i],
                                'document': all_docs_data['documents'][i],
                                'metadata': meta
                            })
                
                if matched_docs:
                    print(f"âœ¨ ë‚ ì§œê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” {len(matched_docs)}ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ìš°ì„ ì ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                    
                    final_ids = [d['id'] for d in matched_docs]
                    final_docs = [d['document'] for d in matched_docs]
                    final_metas = [d['metadata'] for d in matched_docs]
                    
                    return {
                        'ids': [final_ids],
                        'documents': [final_docs],
                        'metadatas': [final_metas]
                    }
                else:
                    print(f"â„¹ï¸ ë‚ ì§œ({query_date.strftime('%Y-%m-%d')})ì™€ ì¼ì¹˜í•˜ëŠ” ë¬¸ì„œëŠ” ì—†ìœ¼ë‚˜, ê´€ë ¨ ë‚´ìš©ì„ ê³„ì† ê²€ìƒ‰í•©ë‹ˆë‹¤.")

            except Exception as e:
                print(f"âš ï¸ íŠ¹ì • ë‚ ì§œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}. ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        
        # ğŸ”¥ NEW: "ìµœì‹ " ì¿¼ë¦¬ì¸ì§€ íŒŒì•…
        is_latest_query = any(word in query.lower() for word in ['ìµœì‹ ', 'ìµœê·¼', 'ìƒˆë¡œìš´', 'ê°€ì¥'])
        
        # ğŸš€ ë¹ ë¥¸ ê°œì„ : ì¿¼ë¦¬ ì „ì²˜ë¦¬ ë° í‚¤ì›Œë“œ í™•ì¥
        enhanced_query = self.preprocess_query(query)
        
        # --- 1ë‹¨ê³„: ì˜ë¯¸ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ (Query Expansion ì‚¬ìš©) ---
        print("1ï¸âƒ£  ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ì‹¤í–‰...")
        expanded_queries = self.expand_query(enhanced_query)
        vector_search_results = {}  # {doc_id: rank}

        for i, exp_query in enumerate(expanded_queries):
            try:
                results = self.collection.query(query_texts=[exp_query], n_results=n_results)
                print(f"   ë²¡í„° ê²€ìƒ‰ {i+1}: {len(results['ids'][0])}ê°œ ê²°ê³¼")
                for rank, doc_id in enumerate(results['ids'][0]):
                    if doc_id not in vector_search_results:
                        vector_search_results[doc_id] = rank + 1 # ë­í¬ëŠ” 1ë¶€í„° ì‹œì‘
            except Exception as e:
                print(f"âŒ '{exp_query}' ë²¡í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        print(f"   ë²¡í„° ê²€ìƒ‰ ì´ {len(vector_search_results)}ê°œ ê³ ìœ  ë¬¸ì„œ")
        
        # --- 2ë‹¨ê³„: ê°•í™”ëœ í‚¤ì›Œë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ---
        print("2ï¸âƒ£  ê°•í™”ëœ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ì‹¤í–‰...")
        keyword_search_results = {} # {doc_id: rank}
        try:
            all_docs = self.collection.get(include=["documents", "metadatas"]) 
            
            # ğŸš€ ë¹ ë¥¸ ê°œì„ : ëŒ€í­ í™•ì¥ëœ í‚¤ì›Œë“œ ë§¤í•‘
            enhanced_keywords = self.get_enhanced_keywords(enhanced_query)
            
            print(f"ğŸ”‘ í™•ì¥ëœ í‚¤ì›Œë“œ: {list(enhanced_keywords)[:8]}...")
            
            scores = []
            for doc_id, document, metadata in zip(all_docs['ids'], all_docs['documents'], all_docs['metadatas']):
                doc_lower = document.lower()
                title_lower = metadata.get('title', '').lower() if metadata else ''
                
                # ğŸš€ ë¹ ë¥¸ ê°œì„ : ì œëª© ê°€ì¤‘ì¹˜ ëŒ€í­ ì¦ê°€ (2ë°° â†’ 5ë°°)
                content_matches = sum(1 for term in enhanced_keywords if term in doc_lower)
                title_matches = sum(1 for term in enhanced_keywords if term in title_lower) * 5  # ì œëª© ë§¤ì¹­ ê°€ì¤‘ì¹˜ ì¦ê°€
                
                # ğŸš€ ë¹ ë¥¸ ê°œì„ : ì •í™•í•œ êµ¬ë¬¸ ë§¤ì¹­ ë³´ë„ˆìŠ¤
                exact_phrase_bonus = 0
                if any(phrase in title_lower for phrase in self.get_exact_phrases(enhanced_query)):
                    exact_phrase_bonus = 10  # ì •í™•í•œ êµ¬ë¬¸ ë§¤ì¹­ ì‹œ ë†’ì€ ë³´ë„ˆìŠ¤
                
                total_score = content_matches + title_matches + exact_phrase_bonus
                
                if total_score > 0:
                    scores.append({'id': doc_id, 'score': total_score})
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë­í¬ ë¶€ì—¬
            sorted_by_score = sorted(scores, key=lambda x: x['score'], reverse=True)
            for rank, item in enumerate(sorted_by_score):
                keyword_search_results[item['id']] = rank + 1
            
            print(f"   í‚¤ì›Œë“œ ê²€ìƒ‰ ì´ {len(keyword_search_results)}ê°œ ë¬¸ì„œ (ìƒìœ„ ì ìˆ˜: {sorted_by_score[0]['score'] if sorted_by_score else 0})")

        except Exception as e:
            print(f"âŒ í‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

        # --- 3ë‹¨ê³„: RRF (Reciprocal Rank Fusion) ë¡œ ê²°ê³¼ ì¬ì •ë ¬ ---
        print("3ï¸âƒ£  RRFë¡œ ê²°ê³¼ ì¬ì •ë ¬...")
        fused_scores = {}
        k = 60  # RRFì˜ ê¸°ë³¸ ìƒìˆ˜
        vector_weight = 1.0
        keyword_weight = 2.0 # ğŸš€ ë¹ ë¥¸ ê°œì„ : í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì¦ê°€ (1.5 â†’ 2.0)

        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜ í•©ì‚°
        for doc_id, rank in vector_search_results.items():
            fused_scores[doc_id] = fused_scores.get(doc_id, 0) + (1 / (k + rank)) * vector_weight

        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜ í•©ì‚°
        for doc_id, rank in keyword_search_results.items():
            fused_scores[doc_id] = fused_scores.get(doc_id, 0) + (1 / (k + rank)) * keyword_weight
            
        # ìµœì¢… ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_fused_ids = sorted(fused_scores.keys(), key=lambda x: fused_scores[x], reverse=True)
        
        print(f"   RRF ìœµí•© ê²°ê³¼: {len(sorted_fused_ids)}ê°œ ë¬¸ì„œ")
        
        if not sorted_fused_ids:
            return None # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜

        # ìµœì¢… ìƒìœ„ n_resultsê°œì˜ ë¬¸ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        top_ids = sorted_fused_ids[:n_results]
        final_results = self.collection.get(ids=top_ids, include=["documents", "metadatas"])
        
        # --- 4ë‹¨ê³„: ë‚ ì§œ ê¸°ë°˜ 2ì°¨ ì •ë ¬ (ìµœì‹ ìˆœ) ---
        print("4ï¸âƒ£  ë‚ ì§œ ê¸°ë°˜ ì •ë ¬ ë° ê°€ì¤‘ì¹˜ ì ìš©...")
        try:
            # ì˜¤ëŠ˜ ë‚ ì§œ ìë™ ê°€ì ¸ì˜¤ê¸°
            current_date = date.today().strftime("%Y-%m-%d")
            
            # idì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ë§¤í•‘
            id_to_data = {}
            for doc_id, doc, meta in zip(final_results['ids'], final_results['documents'], final_results['metadatas']):
                date_str = meta.get('date', '1900-01-01') if meta else '1900-01-01'
                date_weight = self.calculate_date_weight(date_str, current_date)
                
                # RRF ì ìˆ˜ì— ë‚ ì§œ ê°€ì¤‘ì¹˜ ì ìš©
                weighted_score = fused_scores[doc_id] * date_weight
                
                id_to_data[doc_id] = {
                    'document': doc,
                    'metadata': meta,
                    'date': date_str,
                    'rrf_score': fused_scores[doc_id],
                    'date_weight': date_weight,
                    'final_score': weighted_score
                }
            
            # ğŸ”¥ NEW: 'ìµœì‹ ' ì¿¼ë¦¬ì¼ ê²½ìš° ë‚ ì§œ ìš°ì„  ì •ë ¬, ì•„ë‹ ê²½ìš° ê¸°ì¡´ ì ìˆ˜ ì •ë ¬
            if is_latest_query:
                print("âœ¨ 'ìµœì‹ ' ì¿¼ë¦¬ë¡œ ê°ì§€, ë‚ ì§œ ìš°ì„  ì •ë ¬ ì‹¤í–‰...")
                # ë‚ ì§œ ë¬¸ìì—´ë¡œ ì§ì ‘ ì •ë ¬ (ëŒ€ë¶€ë¶„ì˜ YYYY-MM-DD í˜•ì‹ì—ì„œ ë™ì‘)
                # ë™ì¼ ë‚ ì§œì˜ ê²½ìš° ê¸°ì¡´ ì ìˆ˜ë¡œ 2ì°¨ ì •ë ¬
                sorted_ids = sorted(
                    top_ids,
                    key=lambda x: (id_to_data.get(x, {}).get('date', '1900-01-01'), id_to_data.get(x, {}).get('final_score', 0)),
                    reverse=True
                )
            else:
                # ìµœì¢… ê°€ì¤‘ ì ìˆ˜ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ ìˆœ)
                sorted_ids = sorted(
                    top_ids,
                    key=lambda x: id_to_data[x]['final_score'],
                    reverse=True
                )
            
            # ì •ë ¬ëœ ìˆœì„œë¡œ ê²°ê³¼ ì¬êµ¬ì„±
            final_docs = [id_to_data[doc_id]['document'] for doc_id in sorted_ids]
            final_metas = [id_to_data[doc_id]['metadata'] for doc_id in sorted_ids]
            
            # ì ìˆ˜ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©) - ëª¨ë°”ì¼ ìµœì í™”: ê°„ëµí•˜ê²Œ
            print(f"ğŸ“Š ê¸°ì¤€ì¼: {current_date}, ìƒìœ„ ë¬¸ì„œ ì ìˆ˜:")
            for i, doc_id in enumerate(sorted_ids[:2]):  # ìƒìœ„ 2ê°œë§Œ
                data = id_to_data[doc_id]
                print(f"   {i+1}. ìµœì¢…: {data['final_score']:.4f} [{data['date']}]")
            
            return {
                'ids': [sorted_ids],
                'documents': [final_docs],
                'metadatas': [final_metas]
            }
            
        except Exception as e:
            print(f"âš ï¸ ë‚ ì§œ ì •ë ¬ ì¤‘ ì˜¤ë¥˜ ({e}), RRF ìˆœì„œ ìœ ì§€")
            # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ RRF ìˆœì„œ ìœ ì§€
            id_to_doc = {doc_id: (doc, meta) for doc_id, doc, meta in zip(final_results['ids'], final_results['documents'], final_results['metadatas'])}
            final_docs = [id_to_doc[doc_id][0] for doc_id in top_ids if doc_id in id_to_doc]
            final_metas = [id_to_doc[doc_id][1] for doc_id in top_ids if doc_id in id_to_doc]
            
            return {
                'ids': [top_ids],
                'documents': [final_docs],
                'metadatas': [final_metas]
            }
    
    def generate_answer(self, query: str, context_docs: list, context_metas: list = None):
        """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ë° ì•ˆì „ ì„¤ì • ì™„í™”)"""
        
        context_parts = []
        for i, doc in enumerate(context_docs):
            if context_metas and i < len(context_metas) and context_metas[i]:
                date_val = context_metas[i].get('date', 'ë‚ ì§œ ë¯¸ìƒ')
                title = context_metas[i].get('title', 'ì œëª© ì—†ìŒ')
                context_parts.append(f"ë¬¸ì„œ ì œëª©: {title}\në¬¸ì„œ ë‚ ì§œ: {date_val}\në¬¸ì„œ ë‚´ìš©:\n{doc}")
            else:
                context_parts.append(doc)
        
        context = "\n\n---\n\n".join(context_parts)
        
        today_str = date.today().strftime("%Yë…„ %mì›” %dì¼")
        
        prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ë°©ì†¡í†µì‹ ëŒ€í•™êµ(KNOU)ì˜ ì •ë³´ë¥¼ ê°€ì¥ ê°€ë…ì„± ì¢‹ê²Œ ìš”ì•½í•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤. **ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´(Markdown)ì„ ì‚¬ìš©**í•˜ì—¬, í•µì‹¬ì„ ë¨¼ì € ë³´ì—¬ì£¼ê³  ì„¸ë¶€ ì •ë³´ë¥¼ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ ì´í•´í•˜ë„ë¡ ë‹µë³€ì„ êµ¬ì„±í•´ì£¼ì„¸ìš”.

**ì¤‘ìš”: ì˜¤ëŠ˜ì€ {today_str}ì…ë‹ˆë‹¤. ì´ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹ ì„±ê³¼ ê´€ë ¨ì„±ì„ íŒë‹¨í•´ì£¼ì„¸ìš”.**

**ë‹µë³€ ìƒì„± ê·œì¹™ (Markdown ì‚¬ìš©):**

1.  **ğŸ¯ í•µì‹¬ ìš”ì•½ (ë§¨ ì²˜ìŒì—):**
    *   ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ê°€ì¥ ì¤‘ìš”í•œ ë‹µë³€ì„ **êµµì€ ê¸€ì”¨**ì™€ í•¨ê»˜ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ê°€ì¥ ë¨¼ì € ë³´ì—¬ì£¼ì„¸ìš”.
    *   ê´€ë ¨ ê³µì§€ ë‚ ì§œë¥¼ ë°˜ë“œì‹œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”. (ì˜ˆ: "**2025ë…„ 7ì›” 16ì¼ ê³µì§€ì— ë”°ë¥´ë©´, 2í•™ê¸° ì„±ì ìš°ìˆ˜ì¥í•™ìƒ ì„ ë°œì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤.**")
    *   ìµœì‹  ê³µì§€ë¥¼ ìš”ì²­ë°›ì€ ê²½ìš°, ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ìµœê·¼ ê³µì§€ë“¤ì„ ë‚ ì§œìˆœìœ¼ë¡œ ë‚˜ì—´í•´ì£¼ì„¸ìš”.

2.  **ğŸ”– ì£¼ìš” ì •ë³´ (ì„¹ì…˜ìœ¼ë¡œ êµ¬ë¶„):**
    *   `###` (h3)ì™€ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ìš” ì •ë³´ ì„¹ì…˜ì„ ë‚˜ëˆ„ì„¸ìš”. (ì˜ˆ: `### ğŸ“Œ ì„ ë°œ í™•ì¸ ë°©ë²•`)
    *   ë‚´ìš©ì€ `*`ë¥¼ ì‚¬ìš©í•œ ëª©ë¡(list)ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
    *   í‘œ(Table)ëŠ” ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê°„ê²°í•˜ê²Œ ë§Œë“œì„¸ìš”.

3.  **â­ ê°•ì¡°:**
    *   ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ëŠ” `**êµµê²Œ**` í‘œì‹œí•˜ì—¬ ê°•ì¡°í•˜ì„¸ìš”.

4.  **ì¹œì ˆí•œ ë§íˆ¬:**
    *   ì „ì²´ì ìœ¼ë¡œ ì¹œê·¼í•˜ê³  ëª…í™•í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

5.  **ì •ë³´ì˜ ì •í™•ì„±:**
    *   ì œê³µëœ **ì°¸ê³  ë¬¸ì„œ** ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì—†ëŠ” ë‚´ìš©ì€ "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…í™•íˆ ë§í•´ì£¼ì„¸ìš”.

---

**ì‚¬ìš©ì ì§ˆë¬¸:** {query}

**ì°¸ê³  ë¬¸ì„œ:**
{context}

**ë‹µë³€ (Markdown í˜•ì‹):**
"""

        try:
            # ì•ˆì „ ì„¤ì • ì™„í™” ë° ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
            response = self.gen_model.generate_content(
                prompt,
                stream=True,
                safety_settings={
                    'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE',
                    'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE',
                    'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE',
                    'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE',
                }
            )
            for chunk in response:
                yield chunk.text
        except Exception as e:
            print(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            yield "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë™ì•ˆ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def chat(self, query: str):
        """ì „ì²´ RAG í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„±)"""
        print(f"ğŸ” ê²€ìƒ‰ ì¤‘: '{query}'")
        
        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        search_results = self.search_documents(query)
        if not search_results or not search_results['documents'][0]:
            yield "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            return

        # 2. ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
        documents = search_results['documents'][0]
        metadatas = search_results.get('metadatas', [None])[0] if search_results.get('metadatas') else None
        print(f"ğŸ“š {len(documents)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # 3. ë‹µë³€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
        print("ğŸ’­ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± ì¤‘...")
        yield from self.generate_answer(query, documents, metadatas)
        print("\nâœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        chatbot = KNOUChatbot()
        # chatbot.interactive_chat() # ì´ì œ ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©
        # ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš© ì‹œ ì˜ˆì‹œ:
        # for answer_chunk in chatbot.chat("ì˜¤ëŠ˜ í•™êµ ì¶œì„ ì²´í¬ ë°©ë²•ì€?"):
        #     print(answer_chunk, end='', flush=True)
        # print() # ë§ˆì§€ë§‰ ì¤„ ì¶œë ¥

        # ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ - ì´ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬í•˜ì„¸ìš”!
        # chatbot.interactive_chat()
        
        print("âœ… ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. FastAPI ì„œë²„ë¥¼ í†µí•´ ì‚¬ìš©í•˜ì„¸ìš”.")

    except Exception as e:
        print(f"âŒ ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main() 